{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e197d7fc",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6852c667",
   "metadata": {},
   "source": [
    "# 10.0 Monitoring GPU within Kubernetes Cluster\n",
    "## (part of Lab 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fef5a",
   "metadata": {},
   "source": [
    "In this notebook, you'll learn to monitor and manage GPU resources across a K8s cluster using [NVIDIA Data Center GPU Manager (DCGM)](https://developer.nvidia.com/dcgm).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85539452",
   "metadata": {},
   "source": [
    "**[10.1 Deploy Prometheus](#10.1-Deploy-Prometheus)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.1.1 Configuration File](#10.1.1-Configuration-File)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.1.2 Exercise: Override a Configuration Value](#10.1.2-Exercise:-Override-a-Configuration-Value)<br>\n",
    "**[10.2 Deploy `dcgm-exporter`](#10.2-Deploy-dcgm-exporter)<br>**\n",
    "**[10.3 Explore Prometheus and Grafana](#10.3-Explore-Prometheus-and-Grafana)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.3.1 Exercise: Set Up a Dashboard](#10.3.1-Exercise:-Set-Up-a-Dashboard)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.3.2 Shutdown](#10.3.2-Shutdown)<br>\n",
    "\n",
    "\n",
    "Monitoring systems includes collecting/storing metrics, visualizing results, and alerting on specific observed conditions.\n",
    "DCGM is a suite of tools that includes active health monitoring, comprehensive diagnostics, system alerts, and governance policies for the GPU cluster. \n",
    "Metrics are collected with the open-source tool [Prometheus](https://prometheus.io/) and visualized with the [Grafana](https://grafana.com/) tool to create rich dashboards.  \n",
    "\n",
    "To gather GPU telemetry in Kubernetes, we will use [dcgm-exporter](https://docs.nvidia.com/datacenter/cloud-native/kubernetes/dcgme2e.html#gpu-telemetry), which exposes GPU metrics in a format that can be scraped by Prometheus and visualized using Grafana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a0634",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you are starting with a K8s cluster that is GPU-enabled with feature discovery.  Let's ensure that by stopping and restarting a cluster and bringing it to a known state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1376d14",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üôÑ  \"minikube\" profile does not exist, trying anyways.\n",
      "üíÄ  Removed all traces of the \"minikube\" cluster.\n",
      "üòÑ  minikube v1.23.2 on Ubuntu 20.04 (docker/amd64)\n",
      "‚ú®  Using the none driver based on user configuration\n",
      "üëç  Starting control plane node minikube in cluster minikube\n",
      "ü§π  Running on localhost (CPUs=4, Memory=15818MB, Disk=297738MB) ...\n",
      "‚ÑπÔ∏è  OS release is Ubuntu 20.04.5 LTS\n",
      "üê≥  Preparing Kubernetes v1.22.2 on Docker 23.0.2 ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "    ‚ñ™ Generating certificates and keys ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "    ‚ñ™ Booting up control plane ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "    ‚ñ™ Configuring RBAC rules ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "ü§π  Configuring local host environment ...\n",
      "\n",
      "‚ùó  The 'none' driver is designed for experts who need to integrate with an existing VM\n",
      "üí°  Most users should use the newer 'docker' driver instead, which does not require root!\n",
      "üìò  For more information, see: https://minikube.sigs.k8s.io/docs/reference/drivers/none/\n",
      "\n",
      "‚ùó  kubectl and minikube configuration will be stored in /root\n",
      "‚ùó  To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run:\n",
      "\n",
      "    ‚ñ™ sudo mv /root/.kube /root/.minikube $HOME\n",
      "    ‚ñ™ sudo chown -R $USER $HOME/.kube $HOME/.minikube\n",
      "\n",
      "üí°  This can also be done automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=true\n",
      "üîé  Verifying Kubernetes components...\n",
      "    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n",
      "üåü  Enabled addons: storage-provisioner, default-storageclass\n",
      "üèÑ  Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default\n",
      "\"nvdp\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n",
      "Release \"nvdp\" does not exist. Installing it now.\n",
      "NAME: nvdp\n",
      "LAST DEPLOYED: Thu Jul 27 07:43:08 2023\n",
      "NAMESPACE: nvidia-device-plugin\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "\"nvgfd\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n",
      "Release \"nvgfd\" does not exist. Installing it now.\n",
      "NAME: nvgfd\n",
      "LAST DEPLOYED: Thu Jul 27 07:43:09 2023\n",
      "NAMESPACE: gpu-feature-discovery\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n"
     ]
    }
   ],
   "source": [
    "# Delete and restart K8s\n",
    "!minikube delete\n",
    "!minikube start --driver=none\n",
    "# Install the GPU device plugin with Helm\n",
    "!helm repo add nvdp https://nvidia.github.io/k8s-device-plugin \\\n",
    "   && helm repo update\n",
    "!helm upgrade -i nvdp nvdp/nvidia-device-plugin \\\n",
    "  --namespace nvidia-device-plugin \\\n",
    "  --create-namespace \\\n",
    "  --version 0.13.0\n",
    "# Install GPU feature discovery with Helm\n",
    "!helm repo add nvgfd https://nvidia.github.io/gpu-feature-discovery \\\n",
    "    && helm repo update\n",
    "!helm upgrade -i nvgfd nvgfd/gpu-feature-discovery \\\n",
    "  --version 0.7.0 \\\n",
    "  --namespace gpu-feature-discovery \\\n",
    "  --create-namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cba596",
   "metadata": {},
   "source": [
    "Check the list of Helm charts installed with the `helm list` command (see the [Helm documentation](https://helm.sh/docs/helm/helm_list/)). The `--filter` option allows filtering by name.  Use the `--output` option to specify the output format (\"json\", \"table\", or \"yaml\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8434108",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME \tNAMESPACE            \tREVISION\tUPDATED                                \tSTATUS  \tCHART                      \tAPP VERSION\n",
      "nvdp \tnvidia-device-plugin \t1       \t2023-07-27 07:43:08.720989373 +0000 UTC\tdeployed\tnvidia-device-plugin-0.13.0\t0.13.0     \n",
      "nvgfd\tgpu-feature-discovery\t1       \t2023-07-27 07:43:09.398965504 +0000 UTC\tdeployed\tgpu-feature-discovery-0.7.0\t0.7.0      \n"
     ]
    }
   ],
   "source": [
    "# check the list of charts\n",
    "!helm list -A  --output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7a89b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- app_version: 0.13.0\n",
      "  chart: nvidia-device-plugin-0.13.0\n",
      "  name: nvdp\n",
      "  namespace: nvidia-device-plugin\n",
      "  revision: \"1\"\n",
      "  status: deployed\n",
      "  updated: 2023-07-27 07:43:08.720989373 +0000 UTC\n"
     ]
    }
   ],
   "source": [
    "# Filter the list of charts\n",
    "!helm list -A --filter \"nvdp\" --output yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1fe7f",
   "metadata": {},
   "source": [
    "---\n",
    "# 10.1 Deploy Prometheus\n",
    "\n",
    "The first step is to deploy Prometheus to the cluster, as `dcgm-exporter` depends on Prometheus. If we do this out of order we will get an error.  \n",
    "\n",
    "<img  src=\"images/k8s/prometheus-architecture.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e16ba",
   "metadata": {},
   "source": [
    "In the previous notebook, our steps for deployment with Helm were simply to add the appropriate repository, then install with options itemized.  For Prometheus, we have an additional intermediate step.  We need to modify the configuration values before installation.  Our steps are:\n",
    "1. Add the Prometheus repository\n",
    "2. Get the `kube-prometheus-stack` values file and modify it for our configuration\n",
    "3. Install Prometheus with Helm using the updated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f95a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"prometheus-community\" has been added to your repositories\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n"
     ]
    }
   ],
   "source": [
    "# Add the prometheus-community repo\n",
    "!helm repo add prometheus-community \\\n",
    "    https://prometheus-community.github.io/helm-charts \\\n",
    "    && helm repo update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b6bdc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      \tCHART VERSION\tAPP VERSION\tDESCRIPTION                                       \n",
      "prometheus-community/kube-prometheus-stack\t44.3.1       \tv0.62.0    \tkube-prometheus-stack collects Kubernetes manif...\n"
     ]
    }
   ],
   "source": [
    "# Find the exact name\n",
    "!helm search repo prometheus --version 44.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac40f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use inspect to export the values YAML file\n",
    "!helm inspect values prometheus-community/kube-prometheus-stack \\\n",
    "    --version 44.3 > ./kube-prometheus-stack.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb185a",
   "metadata": {},
   "source": [
    "## 10.1.1 Configuration File\n",
    "The [kube-prometheus-stack.values](kube-prometheus-stack.values) file is quite large. You can take a look to get a sense of the many configuration settings possible in deployment. Depending on your own use case, you may need to modify the file before deployment.  In this class, there is a file with modifications already preloaded.  You can see the changes \n",
    "by running a `diff` of the two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59721ed7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765c765,769\n",
      "< \n",
      "---\n",
      ">   grafana.ini:\n",
      ">     server:\n",
      ">       domain: \"\"\n",
      ">       root_url: \"\"\n",
      ">       serve_from_subpath: true\n",
      "774c778\n",
      "<     enabled: false\n",
      "---\n",
      ">     enabled: true\n",
      "799c803\n",
      "<     path: /\n",
      "---\n",
      ">     path: /grafana\n",
      "2789c2793\n",
      "<     serviceMonitorSelectorNilUsesHelmValues: true\n",
      "---\n",
      ">     serviceMonitorSelectorNilUsesHelmValues: false\n"
     ]
    }
   ],
   "source": [
    "CONFIG_DIR = \"/dli/task/kubernetes-config\"\n",
    "!diff kube-prometheus-stack.values $CONFIG_DIR/kube-prometheus-stack-v44.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2a312",
   "metadata": {},
   "source": [
    "One area of the configuration file that is of particular interest to us, is the configuration of Grafana.  Here are the Grafana settings in the preloaded version of the values file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f6e8e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grafana:\n",
      "  enabled: true\n",
      "  namespaceOverride: \"\"\n",
      "\n",
      "  ## ForceDeployDatasources Create datasource configmap even if grafana deployment has been disabled\n",
      "  ##\n",
      "  forceDeployDatasources: false\n",
      "\n",
      "  ## ForceDeployDashboard Create dashboard configmap even if grafana deployment has been disabled\n",
      "  ##\n",
      "  forceDeployDashboards: false\n",
      "\n",
      "  ## Deploy default dashboards\n",
      "  ##\n",
      "  defaultDashboardsEnabled: true\n",
      "\n",
      "  ## Timezone for the default dashboards\n",
      "  ## Other options are: browser or a specific timezone, i.e. Europe/Luxembourg\n",
      "  ##\n",
      "  defaultDashboardsTimezone: utc\n",
      "\n",
      "  adminPassword: prom-operator\n",
      "  grafana.ini:\n",
      "    server:\n",
      "      domain: \"\"\n",
      "      root_url: \"\"\n",
      "      serve_from_subpath: true\n",
      "  rbac:\n",
      "    ## If true, Grafana PSPs will be created\n",
      "    ##\n",
      "    pspEnabled: false\n",
      "\n",
      "  ingress:\n",
      "    ## If true, Grafana Ingress will be created\n",
      "    ##\n",
      "    enabled: true\n",
      "\n",
      "    ## IngressClassName for Grafana Ingress.\n",
      "    ## Should be provided if Ingress is enable.\n",
      "    ##\n",
      "    # ingressClassName: nginx\n",
      "\n",
      "    ## Annotations for Grafana Ingress\n",
      "    ##\n",
      "    annotations: {}\n",
      "      # kubernetes.io/ingress.class: nginx\n",
      "      # kubernetes.io/tls-acme: \"true\"\n",
      "\n",
      "    ## Labels to be added to the Ingress\n",
      "    ##\n",
      "    labels: {}\n",
      "\n",
      "    ## Hostnames.\n",
      "    ## Must be provided if Ingress is enable.\n",
      "    ##\n",
      "    # hosts:\n",
      "    #   - grafana.domain.com\n",
      "    hosts: []\n",
      "\n",
      "    ## Path for grafana ingress\n",
      "    path: /grafana\n"
     ]
    }
   ],
   "source": [
    "!cat $CONFIG_DIR/kube-prometheus-stack-v44.values | grep -A 60 grafana:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399a08f",
   "metadata": {},
   "source": [
    "There are a few more changes to the config file needed.  To access the Grafana webpage, the \"domain\", \"root_url\", and \"hosts\" parameters have to point to your particular GPU instance. Each student GPU instance has a unique URL, which we need to extract.  You could directly modify the values file, but as an exercise, you'll do this with an override to the `helm install` command instead, using the `--set` option. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065237c8",
   "metadata": {},
   "source": [
    "## 10.1.2 Exercise: Override a Configuration Value\n",
    "To override a value in the configuration YAML file, use the `--set` option during installation. \n",
    "the reference to a particular key can be found by it's hierarchy, separated by dots, taking care to escape actual dots in the name!\n",
    "As an example, the reference to the \"Grafana server domain\" is in the hierarchy `grafana`->`grafana.ini`->`server`->`domain`. Therefore, the `--set` option is of the form:\n",
    "\n",
    "```\n",
    "--set grafana.'grafana\\.ini'.server.domain=\"your.domain.here\"\n",
    "```\n",
    "\n",
    "Using the helper cell below, determine the \"domain\", \"root_url\", and \"host\" values.  Then complete the `helm install` command with the correct values and run it to deploy Prometheus. \n",
    "\n",
    "There is no precise solution to look at because every student has a unique host URL.  If you get stuck, you can look at the [example solution](solutions/ex10.1.2.ipynb), which should give you an idea of the correct pattern. <br>*Note: the example solution will not be your exact solution!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca36a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var root_url = 'http://' + window.location.hostname + '/grafana';\n",
       "element.append(root_url);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "var root_url = 'http://' + window.location.hostname + '/grafana';\n",
    "element.append(root_url);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc599d",
   "metadata": {},
   "source": [
    "With the configuration changes in place, go ahead and deploy the Prometheus application. Then we can verify that Prometheus is deployed with the `kubectl get pods` command using the option `--namespace prometheus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf58ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: INSTALLATION FAILED: Ingress.extensions \"kube-prometheus-stack-1690443793-grafana\" is invalid: spec.rules[0].host: Invalid value: \"FIXME\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n"
     ]
    }
   ],
   "source": [
    "# TODO Replace the FIXMEs with the correct setting values and deploy Prometheus\n",
    "# This should take around 30 seconds\n",
    "!helm install prometheus-community/kube-prometheus-stack \\\n",
    "   --version 44.3 \\\n",
    "   --create-namespace --namespace prometheus \\\n",
    "   --generate-name \\\n",
    "   --values $CONFIG_DIR/kube-prometheus-stack-v44.values \\\n",
    "   --set grafana.'grafana\\.ini'.server.domain=\"FIXME\" \\\n",
    "   --set grafana.'grafana\\.ini'.server.root_url=\"FIXME\" \\\n",
    "   --set grafana.ingress.hosts[0]=\"FIXME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79cbc159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS              RESTARTS   AGE\n",
      "kube-prometheus-stack-1690-operator-7ff78d85c9-tjjzt              0/1     ContainerCreating   0          1s\n",
      "kube-prometheus-stack-1690443793-grafana-6d4bc86d79-xmkts         0/3     ContainerCreating   0          1s\n",
      "kube-prometheus-stack-1690443793-kube-state-metrics-5b48fcnjxgk   0/1     ContainerCreating   0          1s\n",
      "kube-prometheus-stack-1690443793-prometheus-node-exporter-qvsm8   0/1     Pending             0          1s\n"
     ]
    }
   ],
   "source": [
    "# Check prometheus pods. Should be \"Running\" after a \"ContainerCreating\" status\n",
    "!kubectl get pods --namespace prometheus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e110f03",
   "metadata": {},
   "source": [
    "---\n",
    "# 10.2 Deploy `dcgm-exporter`\n",
    "\n",
    "The [dcgm-exporter](https://github.com/NVIDIA/dcgm-exporter) project was built to expose DCGM GPU metrics to Prometheus. Now that Prometheus is deployed, we can deploy `dcgm-exporter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c0e22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"gpu-helm-charts\" has been added to your repositories\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "...Successfully got an update from the \"gpu-helm-charts\" chart repository\n",
      "...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n"
     ]
    }
   ],
   "source": [
    "! helm repo add gpu-helm-charts https://nvidia.github.io/dcgm-exporter/helm-charts \\\n",
    "  && helm repo update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c8c520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: dcgm-exporter-1690443815\n",
      "LAST DEPLOYED: Thu Jul 27 07:43:35 2023\n",
      "NAMESPACE: grafana\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "1. Get the application URL by running these commands:\n",
      "  export POD_NAME=$(kubectl get pods -n grafana -l \"app.kubernetes.io/name=dcgm-exporter,app.kubernetes.io/instance=dcgm-exporter-1690443815\" -o jsonpath=\"{.items[0].metadata.name}\")\n",
      "  kubectl -n grafana port-forward $POD_NAME 8080:9400 &\n",
      "  echo \"Visit http://127.0.0.1:8080/metrics to use your application\"\n",
      "daemonset.apps/dcgm-exporter created\n",
      "service/dcgm-exporter created\n"
     ]
    }
   ],
   "source": [
    "! helm install gpu-helm-charts/dcgm-exporter \\\n",
    "   --create-namespace --namespace grafana \\\n",
    "   --generate-name \n",
    "!kubectl create -f https://raw.githubusercontent.com/NVIDIA/dcgm-exporter/master/dcgm-exporter.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79f868",
   "metadata": {},
   "source": [
    "In order to expose Grafana on the class instance, we need to patch the configuration using the [kubectl patch](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/) command.  We need to specify the port and a password.  This patch will override the previous settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a237767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec:\n",
      "  type: NodePort\n",
      "  ports:\n",
      "    - port: 80\n",
      "      nodePort: 31091\n",
      "      name: grafana\n"
     ]
    }
   ],
   "source": [
    "# List the Grafana patch\n",
    "!cat $CONFIG_DIR/grafana-patch.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e945bb",
   "metadata": {},
   "source": [
    "In the next few cells, we will: \n",
    "1. Check the status of the Grafana service using the `kubectl get svc` command\n",
    "1. Make the patch using `kubectl patch svc`\n",
    "1. Check the status again to see if there is a change after applying the patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "586a275d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\n",
      "kube-prometheus-stack-1690443793-grafana   ClusterIP   10.104.134.199   <none>        80/TCP    4s\n"
     ]
    }
   ],
   "source": [
    "# Check the status - note the TYPE and PORT for patching\n",
    "!kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "674f6c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/kube-prometheus-stack-1690443793-grafana patched\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# get the GRAFANA_NAME\n",
    "GRAFANA_NAME=$(kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana -o custom-columns=NAME:.metadata.name --no-headers)\n",
    "\n",
    "# Apply the patch\n",
    "kubectl patch svc $GRAFANA_NAME \\\n",
    "   -n prometheus \\\n",
    "   --patch \"$(cat /dli/task/kubernetes-config/grafana-patch.yaml)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94136cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\n",
      "kube-prometheus-stack-1690443793-grafana   NodePort   10.104.134.199   <none>        80:31091/TCP   4s\n"
     ]
    }
   ],
   "source": [
    "# Check the status again - note the TYPE and PORT changes\n",
    "!kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343699f",
   "metadata": {},
   "source": [
    "---\n",
    "# 10.3 Explore Prometheus and Grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3ff64",
   "metadata": {},
   "source": [
    "The Grafana interface to Prometheus metrics is now exposed.  \n",
    "[Open Grafana!](/grafana/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32d359",
   "metadata": {},
   "source": [
    "Grafana greets you with a dark blue page. To login, use: \n",
    "- Username: `admin` \n",
    "- Password: `prom-operator` \n",
    "\n",
    "The password was originally set in the `kube-prometheus-stack.values` file. If successful, your page should look similar to this:\n",
    "\n",
    "<img src=\"images/k8s/grafana_page1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be923e",
   "metadata": {},
   "source": [
    "What's next?  Set up a dashboard by importing the NVIDIA DCGM Exporter Dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de9bb72",
   "metadata": {},
   "source": [
    "## 10.3.1 Exercise: Set Up a Dashboard\n",
    "For this exercise, follow the instructions in the [GPU telemetry documentation](https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/dcgm-exporter.html?highlight=grafana#dcgm-dashboard-in-grafana) section titled \"DCGM Dashboard in Grafana\". Please STOP after this section and do NOT continue into the next section titled \"Viewing Metrics for Running Applications\", as this will cause errors later in the course code. \n",
    "\n",
    "Basic steps from the instructions:\n",
    "1. Log in\n",
    "2. Select \"+Import\" from the Dashboards menu\n",
    "3. Load `https://grafana.com/grafana/dashboards/12239`\n",
    "4. Select \"Prometheus\" in the \"Prometheus\" slot\n",
    "5. Click \"Import\" to see the dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dcdcd",
   "metadata": {},
   "source": [
    "## 10.3.2 Shutdown\n",
    "Clean up your environment by shutting down K8s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ca203c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ  Uninstalling Kubernetes v1.22.2 using kubeadm ...\n",
      "üî•  Deleting \"minikube\" in none ...\n",
      "üíÄ  Removed all traces of the \"minikube\" cluster.\n",
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# Shut down K8s\n",
    "!minikube delete\n",
    "!docker kill $(docker ps -q)\n",
    "# Check for clean environment - this should be empty\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f066cc",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Deployed a Prometheus server\n",
    "- Modified initialization configurations with settings in `helm install`\n",
    "- Patched a service with K8s for your environment\n",
    "- Explored tools for monitoring activity on your production application\n",
    "\n",
    "Next, you'll deploy a conversational AI Riva application on K8s. <br>\n",
    "Move on to [Deploy Riva](011_K8s_Deploy_Riva.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f56e7",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
